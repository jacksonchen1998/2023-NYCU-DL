{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.data_utils import InputExample\n",
    "from openprompt import PromptForClassification\n",
    "from openprompt import PromptDataLoader\n",
    "from openprompt.prompts import SoftTemplate\n",
    "from openprompt.plms import load_plm\n",
    "from openprompt.prompts import ManualVerbalizer\n",
    "import pandas\n",
    "import warnings\n",
    "import torch\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "train_tsvreader = pandas.read_csv(\"train.tsv\",sep='\\t')\n",
    "train_data      = []\n",
    "# [TODO] \n",
    "# Load training data\n",
    "for i in range(len(train_tsvreader)):\n",
    "    train_data.append(InputExample(guid=i,\n",
    "                                   text_a=train_tsvreader['sentence'][i],\n",
    "                                   label=train_tsvreader['label'][i],\n",
    "                                    ))\n",
    "\n",
    "valid_tsvreader = pandas.read_csv(\"test.tsv\",sep='\\t')\n",
    "test_data       = []\n",
    "# [TODO] \n",
    "# Load testing data\n",
    "for i in range(len(valid_tsvreader)):\n",
    "    test_data.append(InputExample(guid=i,\n",
    "                                   text_a=valid_tsvreader['sentence'][i],\n",
    "                                   label=valid_tsvreader['label'][i],\n",
    "                                   ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model and template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plm, tokenizer, model_config, WrapperClass = load_plm('bert', 'bert-base-uncased')\n",
    "\n",
    "template    = '{\"placeholder\":\"text_a\"} It was {\"mask\"}'\n",
    "soft_tokens = 8\n",
    "mytemplate  = SoftTemplate(model=plm, text=template, tokenizer=tokenizer,\n",
    "                    num_tokens=soft_tokens, initialize_from_vocab=True)\n",
    "\n",
    "classes = [ # There are two classes in Sentiment Analysis, one for negative and one for positive\n",
    "    \"0\",\n",
    "    \"1\"\n",
    "]\n",
    "promptVerbalizer = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"0\": [\"bad\",\"terrible\",\"disgusting\",\"horrible\"],\n",
    "        \"1\": [\"good\", \"wonderful\", \"great\",\"excellent\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_model = PromptForClassification(\n",
    "    plm=plm,\n",
    "    template=mytemplate,\n",
    "    verbalizer=promptVerbalizer,\n",
    "    freeze_plm=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = PromptDataLoader(dataset=train_data, template=mytemplate, tokenizer=tokenizer,\n",
    "    tokenizer_wrapper_class=WrapperClass, max_seq_length=256, decoder_max_length=3,\n",
    "    batch_size=4,shuffle=True, teacher_forcing=False, predict_eos_token=False,\n",
    "    truncate_method=\"head\")\n",
    "\n",
    "validation_dataloader = PromptDataLoader(dataset=test_data, template=mytemplate, tokenizer=tokenizer,\n",
    "    tokenizer_wrapper_class=WrapperClass, max_seq_length=256, decoder_max_length=3,\n",
    "    batch_size=4,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
    "    truncate_method=\"head\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_grouped_parameters = [p for n, p in prompt_model.named_parameters() if p.requires_grad]\n",
    "\n",
    "# Using different optimizer for prompt parameters and model parameters\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr= 5e-5, eps=1e-8)\n",
    "\n",
    "total_epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=200, num_training_steps=len(train_dataloader)*total_epochs)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    tot_loss = 0\n",
    "    prompt_model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        logits = prompt_model(batch)\n",
    "        labels = batch['label']\n",
    "        loss = loss_func(logits, labels)\n",
    "        loss.backward()\n",
    "        tot_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step %100 ==1:\n",
    "            print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds = []\n",
    "alllabels = []\n",
    "for step, inputs in enumerate(validation_dataloader):\n",
    "    logits = prompt_model(inputs)\n",
    "    labels = inputs['label']\n",
    "    alllabels.extend(labels.cpu().tolist())\n",
    "    allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "\n",
    "acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
    "loss = loss_func(torch.tensor(allpreds), torch.tensor(alllabels))\n",
    "print(\"Accuracy: {}, Loss: {}\".format(acc, loss))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
