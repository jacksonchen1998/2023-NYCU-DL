{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.data_utils import InputExample\n",
    "from openprompt import PromptForClassification\n",
    "from openprompt import PromptDataLoader\n",
    "from openprompt.prompts import SoftTemplate\n",
    "from openprompt.plms import load_plm\n",
    "from openprompt.prompts import ManualVerbalizer\n",
    "import pandas\n",
    "\n",
    "# Load data\n",
    "train_tsvreader = pandas.read_csv(\"train.tsv\",sep='\\t')\n",
    "train_data      = []\n",
    "# [TODO] \n",
    "# Load training data\n",
    "\n",
    "\n",
    "valid_tsvreader = pandas.read_csv(\"dev.tsv\",sep='\\t')\n",
    "test_data       = []\n",
    "# [TODO] \n",
    "# Load testing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model and template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plm, tokenizer, model_config, WrapperClass = load_plm('bert', 'bert-base-uncased')\n",
    "\n",
    "template    = ''  # [TODO] Define a template\n",
    "soft_tokens =     # [TODO] number of soft tokens\n",
    "mytemplate  = SoftTemplate(model=plm, text=template, tokenizer=tokenizer,\n",
    "                    num_tokens=soft_tokens, initialize_from_vocab=True)\n",
    "\n",
    "classes = [ # There are two classes in Sentiment Analysis, one for negative and one for positive\n",
    "    \"0\",\n",
    "    \"1\"\n",
    "]\n",
    "promptVerbalizer = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"0\": [\"bad\",\"terrible\",\"disgusting\",\"horrible\"],\n",
    "        \"1\": [\"good\", \"wonderful\", \"great\",\"excellent\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_model =      #[TODO] Combine Template and Verbalizer into a PromptModel\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = PromptDataLoader(\n",
    "    #[TODO] \n",
    ")\n",
    "valid_dataloader = PromptDataLoader(\n",
    "    #[TODO] \n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AdamW,\n",
    ")\n",
    "\n",
    "optimizer_grouped_parameters = # [TODO] freeze parameter of encoder, only update soft tokens \n",
    "\n",
    "# Using different optimizer for prompt parameters and model parameters\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr= # [TODO])\n",
    "\n",
    "for epoch in range(# [TODO] number of epochs):\n",
    "    # [TODO]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
