{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.data_utils import InputExample\n",
    "from openprompt import PromptForClassification\n",
    "from openprompt import PromptDataLoader\n",
    "from openprompt.prompts import SoftTemplate\n",
    "from openprompt.plms import load_plm\n",
    "from openprompt.prompts import ManualVerbalizer\n",
    "import pandas\n",
    "\n",
    "# Load data\n",
    "train_tsvreader = pandas.read_csv(\"train.tsv\",sep='\\t')\n",
    "train_data      = []\n",
    "# [TODO] \n",
    "# Load training data\n",
    "for i in range(len(train_tsvreader)):\n",
    "    train_data.append(InputExample(guid=i,\n",
    "                                   text_a=train_tsvreader['sentence'][i],\n",
    "                                   text_b=None,\n",
    "                                   label=train_tsvreader['label'][i]))\n",
    "\n",
    "valid_tsvreader = pandas.read_csv(\"test.tsv\",sep='\\t')\n",
    "test_data       = []\n",
    "# [TODO] \n",
    "# Load testing data\n",
    "for i in range(len(valid_tsvreader)):\n",
    "    test_data.append(InputExample(guid=i,\n",
    "                                   text_a=valid_tsvreader['sentence'][i],\n",
    "                                   text_b=None,\n",
    "                                   label=valid_tsvreader['label'][i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model and template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plm, tokenizer, model_config, WrapperClass = load_plm('bert', 'bert-base-uncased')\n",
    "\n",
    "template    = '{\"placeholder\":\"text_a\"} It was {\"mask\"}'\n",
    "soft_tokens = 8\n",
    "mytemplate  = SoftTemplate(model=plm, text=template, tokenizer=tokenizer,\n",
    "                    num_tokens=soft_tokens, initialize_from_vocab=True)\n",
    "\n",
    "classes = [ # There are two classes in Sentiment Analysis, one for negative and one for positive\n",
    "    \"0\",\n",
    "    \"1\"\n",
    "]\n",
    "promptVerbalizer = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"0\": [\"bad\",\"terrible\",\"disgusting\",\"horrible\"],\n",
    "        \"1\": [\"good\", \"wonderful\", \"great\",\"excellent\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_model = PromptForClassification(\n",
    "    plm=plm,\n",
    "    template=mytemplate,\n",
    "    verbalizer=promptVerbalizer,\n",
    "    freeze_plm=False\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = PromptDataLoader(\n",
    "    dataset=train_data, \n",
    "    template=template, \n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_wrapper_class=WrapperClass, \n",
    "    max_seq_length=256, \n",
    "    decoder_max_length=3,\n",
    "    batch_size=4,\n",
    "    shuffle=True, \n",
    "    teacher_forcing=False, \n",
    "    predict_eos_token=False,\n",
    "    truncate_method=\"head\"\n",
    ")\n",
    "\n",
    "validation_dataloader = PromptDataLoader(\n",
    "    dataset=test_data, \n",
    "    template=template, \n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_wrapper_class=WrapperClass, \n",
    "    max_seq_length=256, \n",
    "    decoder_max_length=3,\n",
    "    batch_size=4,\n",
    "    shuffle=False, \n",
    "    teacher_forcing=False, \n",
    "    predict_eos_token=False,\n",
    "    truncate_method=\"head\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "optimizer_grouped_parameters = [p for n, p in prompt_model.named_parameters() if p.requires_grad]\n",
    "\n",
    "# Using different optimizer for prompt parameters and model parameters\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr= 5e-5, eps=1e-8)\n",
    "\n",
    "total_epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=200, num_training_steps=len(train_dataloader)*total_epochs)\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    prompt_model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        loss, logits = prompt_model(**batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Epoch {epoch} | Step {step} | Loss {loss}\")\n",
    "\n",
    "    prompt_model.eval()\n",
    "    for step, batch in enumerate(validation_dataloader):\n",
    "        loss, logits = prompt_model(**batch)\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Epoch {epoch} | Step {step} | Loss {loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
