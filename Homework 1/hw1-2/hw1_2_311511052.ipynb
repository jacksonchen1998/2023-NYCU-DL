{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Convolutional Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1\n",
    "<style>\n",
    "    .red {\n",
    "        color: red;\n",
    "    }\n",
    "    .blue {\n",
    "        color: skyblue;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "Please implement a CNN for image recognition by using **CIFAR-10**, then **plot** the <span class=\"blue\">learning curve</span> and the <span class=\"blue\">accuracy rate</span> of training and test data.\n",
    "\n",
    "<center>\n",
    "    <img src = \"./image/acc_1.png\">\n",
    "    <img src = \"./image/loss_1.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "from tqdm import *\n",
    "\n",
    "# use cuda if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN for CIFAR-10\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv4 = torch.nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(32)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(32)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(32)\n",
    "        self.bn4 = torch.nn.BatchNorm2d(32)\n",
    "        self.pool = torch.nn.AvgPool2d(2, 2)\n",
    "        self.fc1 = torch.nn.Linear(32 * 8 * 8, 48)\n",
    "        self.fc2 = torch.nn.Linear(48 * 1 * 1, 10)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load jpg images from folder and convert to tensor\n",
    "def load_data(path):\n",
    "    # data augmentation\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.15),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    data = torchvision.datasets.ImageFolder(path, transform=transform)\n",
    "    return data\n",
    "\n",
    "# load data\n",
    "train_data = load_data('./CIFAR-10/train')\n",
    "test_data = load_data('./CIFAR-10/test')\n",
    "\n",
    "print('Label', train_data.class_to_idx)\n",
    "\n",
    "# show train data image and label\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    img, label = train_data[i]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = data_utils.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_loader = data_utils.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "train_acc, test_acc = [], []\n",
    "train_loss, test_loss = [], []\n",
    "\n",
    "epoch = 100\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for i in range(epoch):\n",
    "    train_loss_sum = 0\n",
    "    train_acc_sum = 0\n",
    "    test_loss_sum = 0\n",
    "    test_acc_sum = 0\n",
    "\n",
    "    model.train()\n",
    "    train_loop = tqdm((train_loader), total=len(train_loader))\n",
    "    for j, (images, labels) in enumerate(train_loop):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_sum += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_acc_sum += (predicted == labels).sum().item()\n",
    "        train_loop.set_description(f'Training, Epoch [{i + 1}/{epoch}]')\n",
    "        train_loop.set_postfix(loss=train_loss_sum / ((j + 1) * batch_size), acc=train_acc_sum / ((j + 1) * batch_size))\n",
    "\n",
    "    model.eval()\n",
    "    test_loop = tqdm((test_loader), total=len(test_loader))\n",
    "    with torch.no_grad():\n",
    "        for j, (images, labels) in enumerate(test_loop):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss_sum += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_acc_sum += (predicted == labels).sum().item()\n",
    "            test_loop.set_description(f'Testing, Epoch [{i + 1}/{epoch}]')\n",
    "            test_loop.set_postfix(loss=test_loss_sum / ((j + 1) * batch_size), acc=test_acc_sum / ((j + 1) * batch_size))\n",
    "\n",
    "    train_loss.append(train_loss_sum / len(train_loader))\n",
    "    train_acc.append(train_acc_sum / len(train_loader.dataset))\n",
    "    test_loss.append(test_loss_sum / len(test_loader))\n",
    "    test_acc.append(test_acc_sum / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train and test accuracy\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(test_acc, label='test')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot train and test loss\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(test_loss, label='test')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2\n",
    "\n",
    "In order to deal with a real-world problem, we may stack some additional layers in the Deep Neural Network which results in the improved accuracy and performance. \n",
    "\n",
    "But it has been found that there is a maximum threshold for depth with the traditional convolutional neural network model. \n",
    "\n",
    "The problem of training a very deep network has been alleviated with the introduction of **ResNet** or residual network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .red {\n",
    "        color: red;\n",
    "    }\n",
    "    .blue {\n",
    "        color: skyblue;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "(a) Construct a **ResNet** with residual blocks for image recognition and **plot** the <span class=\"blue\">learning curve, accuracy rate</span>, \n",
    "\n",
    "try to stack more blocks as you can (ResNet-18 is recommended), you can refer to the <span class=\"blue\">paper</span> for implementation.\n",
    "\n",
    "<center>\n",
    "    <img src = \"./image/acc_2.png\">\n",
    "    <img src = \"./image/loss_2.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
    "                torch.nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsample is not None: # identity mapping used\n",
    "            identity = self.downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet18(torch.nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(64)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.layer1 = self._make_layer(64, 64, 2)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, stride=2) \n",
    "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = torch.nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, block_num, stride=1):\n",
    "        layers = []\n",
    "        layers.append(ResNetBlock(in_channels, out_channels, stride=stride))\n",
    "        for i in range(1, block_num):\n",
    "            layers.append(ResNetBlock(out_channels, out_channels))\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = ResNet18().to(device)\n",
    "\n",
    "res_train_acc, res_test_acc = [], []\n",
    "res_train_loss, res_test_loss = [], []\n",
    "\n",
    "epoch = 100\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet18.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(epoch):\n",
    "    train_loss_sum = 0\n",
    "    train_acc_sum = 0\n",
    "    test_loss_sum = 0\n",
    "    test_acc_sum = 0\n",
    "\n",
    "    resnet18.train()\n",
    "    train_loop = tqdm((train_loader), total=len(train_loader))\n",
    "    for j, (images, labels) in enumerate(train_loop):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = resnet18(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_sum += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_acc_sum += (predicted == labels).sum().item()\n",
    "        train_loop.set_description(f'Training, Epoch [{i + 1}/{epoch}]')\n",
    "        train_loop.set_postfix(loss=train_loss_sum / (j + 1), acc=train_acc_sum / ((j + 1) * batch_size))\n",
    "\n",
    "    resnet18.eval()\n",
    "    test_loop = tqdm((test_loader), total=len(test_loader))\n",
    "    with torch.no_grad():\n",
    "        for j, (images, labels) in enumerate(test_loop):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = resnet18(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss_sum += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_acc_sum += (predicted == labels).sum().item()\n",
    "            test_loop.set_description(f'Testing, Epoch [{i + 1}/{epoch}]')\n",
    "            test_loop.set_postfix(loss=test_loss_sum / (j + 1), acc=test_acc_sum / ((j + 1) * batch_size))\n",
    "\n",
    "    res_train_loss.append(train_loss_sum / len(train_loader))\n",
    "    res_train_acc.append(train_acc_sum / len(train_loader.dataset))\n",
    "    res_test_loss.append(test_loss_sum / len(test_loader))\n",
    "    res_test_acc.append(test_acc_sum / len(test_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train and test accuracy\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(test_acc, label='test')\n",
    "plt.title('ResNet18 Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot train and test loss\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(test_loss, label='test')\n",
    "plt.title('ResNet18 Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "\n",
    "torchsummary.summary(model, (3, 32, 32))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Remove the identity mapping and repeat (a), then make some discussion on the results of (a) and (b). Please **describe** what you found.\n",
    "\n",
    "<center>\n",
    "    <img src = \"./image/acc_3.png\">\n",
    "    <img src = \"./image/loss_3.png\">\n",
    "</center>\n",
    "\n",
    "As we can see, the accuracy rate of ResNet-18 is higher than the accuracy rate of ResNet-18 without identity mapping.\n",
    "\n",
    "Adding identity mapping can help the model to solve the problem of accuracy degrading.\n",
    "\n",
    "Since, the major benefit of identity mapping is that it can enable backpropagation to reach the earlier layers, \n",
    "\n",
    "which is not possible in a deep neural network without residual blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet block wihout identity mapping\n",
    "class ResNetBlock_w(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResNetBlock_w, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
    "                torch.nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) # identity mapping is removed\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet18_without(torch.nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18_without, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(64)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.layer1 = self._make_layer(64, 64, 2)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, stride=2) \n",
    "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = torch.nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, block_num, stride=1):\n",
    "        layers = []\n",
    "        layers.append(ResNetBlock_w(in_channels, out_channels, stride=stride))\n",
    "        for i in range(1, block_num):\n",
    "            layers.append(ResNetBlock_w(out_channels, out_channels))\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_w = ResNet18_without().to(device)\n",
    "\n",
    "res_train_acc, res_test_acc = [], []\n",
    "res_train_loss, res_test_loss = [], []\n",
    "\n",
    "epoch = 100\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet18_w.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(epoch):\n",
    "    train_loss_sum = 0\n",
    "    train_acc_sum = 0\n",
    "    test_loss_sum = 0\n",
    "    test_acc_sum = 0\n",
    "\n",
    "    resnet18_w.train()\n",
    "    train_loop = tqdm((train_loader), total=len(train_loader))\n",
    "    for j, (images, labels) in enumerate(train_loop):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = resnet18_w(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_sum += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_acc_sum += (predicted == labels).sum().item()\n",
    "        train_loop.set_description(f'Training, Epoch [{i + 1}/{epoch}]')\n",
    "        train_loop.set_postfix(loss=train_loss_sum / ((j + 1) * batch_size), acc=train_acc_sum / ((j + 1) * batch_size))\n",
    "\n",
    "    resnet18_w.eval()\n",
    "    test_loop = tqdm((test_loader), total=len(test_loader))\n",
    "    with torch.no_grad():\n",
    "        for j, (images, labels) in enumerate(test_loop):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = resnet18_w(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss_sum += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_acc_sum += (predicted == labels).sum().item()\n",
    "            test_loop.set_description(f'Testing, Epoch [{i + 1}/{epoch}]')\n",
    "            test_loop.set_postfix(loss=test_loss_sum / ((j + 1) * batch_size), acc=test_acc_sum / ((j + 1) * batch_size))\n",
    "\n",
    "    res_train_loss.append(train_loss_sum / len(train_loader))\n",
    "    res_train_acc.append(train_acc_sum / len(train_loader.dataset))\n",
    "    res_test_loss.append(test_loss_sum / len(test_loader))\n",
    "    res_test_acc.append(test_acc_sum / len(test_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "plt.plot(res_train_acc, label='train')\n",
    "plt.plot(res_test_acc, label='test')\n",
    "plt.title('ResNet18 Accuracy without identity mapping')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot loss\n",
    "plt.plot(res_train_loss, label='train')\n",
    "plt.plot(res_test_loss, label='test')\n",
    "plt.title('ResNet18 Loss without identity mapping')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
