{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Feedforward Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1\n",
    "<style>\n",
    "    .red {\n",
    "        color: red;\n",
    "    }\n",
    "    .blue {\n",
    "        color: skyblue;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "Design a FNN model architecture and use the file of the initial weights and biases “<span class=\"blue\">weights.npy</span>”. \n",
    "\n",
    "Run the <span class=\"red\">backpropagation</span> algorithm and use the <span class=\"red\">mini-batch SGD</span> (stochastic gradient descent) \n",
    "$$\n",
    "    \\mathbf{w}^{(\\tau+1)}=\\mathbf{w}^{(\\tau)}-\\eta \\nabla J\\left(\\mathbf{w}^{(\\tau)}\\right)\n",
    "$$\n",
    "to optimize the parameters (<span class=\"blue\">the weights and biases)</span>,\n",
    "where $\\nabla$ is the learning rate. \n",
    "\n",
    "<span class=\"red\">You should implement the FNN training under the following settings:</span>\n",
    "\n",
    "- number of layers: 3\n",
    "- number of neurons in each layer (in order): 2048, 512, 5\n",
    "- activation function for each layer (in order): relu, relu, softmax\n",
    "- number of training epochs: 30\n",
    "- learning rate: 0.01\n",
    "- batch size: 200\n",
    "- **important note**: For 1(a), <span class=\"red\">DO NOT RESHUFFLE THE DATA.</span> We had already shuffled the data for you.\n",
    "\n",
    "Reshuffling will make <span class=\"blue\">your result differ from our ground-truth result</span>, and <span class=\"red\">any difference will result in reduction of your points.</span>\n",
    "\n",
    "On the same note, when splitting the samples into batches, split them in the given sample order."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .red {\n",
    "        color: red;\n",
    "    }\n",
    "    .blue {\n",
    "        color: skyblue;\n",
    "    }\n",
    "</style>\n",
    "(a) **Plot** the <span class=\"blue\">learning curves</span> of $J(\\mathbf{w})$ and the <span class=\"blue\">accuracy</span> of classification <span class=\"blue\">for every 25 iterations</span>, with training data as well as test data, also, **show** the final loss and accuracy values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .red {\n",
    "        color: red;\n",
    "    }\n",
    "    .blue {\n",
    "        color: skyblue;\n",
    "    }\n",
    "</style>\n",
    "(b) **Repeat 1(a)** by considering <span class=\"red\">zero initialization</span> for the model weights. And **make some discussion.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2\n",
    "<style>\n",
    "    .red {\n",
    "        color: red;\n",
    "    }\n",
    "    .blue {\n",
    "        color: skyblue;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "Based on the model in 1, please <span class=\"blue\">implement the dropout layers</span> and apply them <span class=\"blue\">after the first two hidden layers</span>, i.e. the layers with 2048 and 512 neurons. \n",
    "\n",
    "The <span class=\"blue\">dropout rate should be set as 0.2</span> for both layers. \n",
    "\n",
    "Note that the dropout operation <span class=\"blue\">should only be applied in the training phase</span> and should be disabled in the test phase."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) **Train** the model by using the same settings in 1 and **repeat 1(a).**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Based on the experimental results, how the dropout layers affect the model performance and why? Please **make some discussion.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3\n",
    "\n",
    "Based on the model in 1, please implement mini-batch SGD (stochastic gradient descent).\n",
    "\n",
    "In this problem, we need to reshuffle the data in every batch. Note that the other settings remain the same. \n",
    "\n",
    "Please set the random seed as **42**, and please use **random** library that we have imported."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .red {\n",
    "        color: red;\n",
    "    }\n",
    "    .blue {\n",
    "        color: skyblue;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "(a) **Plot** the <span class=\"blue\">learning curves</span> of $J(\\mathbf{w})$ and the classification <span class=\"blue\">accuracy for every 25 iterations.</span> Please **show** the final values of loss and accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .red {\n",
    "        color: red;\n",
    "    }\n",
    "    .blue {\n",
    "        color: skyblue;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "(b) Based on the experimental results, how the <span class=\"blue\">process of reshuffling images</span> affects the model performance and why? Please **make some discussion.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for reading the data and the initial weights and biases.\n",
    "# Note: This is just an example of how to read these files, you can modify the code in your own implementation.\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "train_x, train_y = np.load('train_x.npy'), np.load('train_y.npy')\n",
    "test_x, test_y = np.load('test_x.npy'), np.load('test_y.npy')\n",
    "\n",
    "print('shape of data:')\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "\n",
    "checkpoint = np.load('weights.npy', allow_pickle=True).item()\n",
    "init_weights = checkpoint['w']\n",
    "init_biases = checkpoint['b']\n",
    "\n",
    "print('shape of weights:')\n",
    "for w in init_weights:\n",
    "    print(w.shape)\n",
    "    \n",
    "\n",
    "print()\n",
    "\n",
    "print('shape of biases:')\n",
    "for b in init_biases:\n",
    "    print(b.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77efda19133223beae4d8202f64c0ed7ef77e02bd33099328534a5c00204ca3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
